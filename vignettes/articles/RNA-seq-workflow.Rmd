---
title: "RNA-seq-workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{RNA-seq-workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## Overview

Below, I will illustrate some of the functions present in the `coriell`
package by walking through a typical RNA-seq workflow, starting with checking
data for quality and then progressing through quantifying with [Salmon](https://salmon.readthedocs.io/en/latest/salmon.html) 
and performing differential expression analysis with `edgeR`. 

**update (2024-02)** Since writing this vignette I have updated my preferred
TE workflow away from REdiscoverTE and towards using a bootstrapped based 
quantification method instead. This vignette still contains many examples
of the `coriell` package and typical RNA-seq analysis steps.

## Checking sequences for quality

The first step in any high-throughput analysis should be to check your reads for
quality. [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) is
the *de facto* tool for this job.

To run `fastqc` enter the directory where your fastq files are saved and run:

```
fastqc *.fastq.gz
```

Additional arguments can be passed to the program to increase the number of 
parallel processes as well as specify the output directory. e.g. 
`fastqc *.fq.gz --threads 12 --outdir $OUT`

An especially useful step following `fastqc` is to run the program [MultiQC](https://multiqc.info/)
which automatically scans a directory and summarizes all QC files it finds. If 
you have many samples `multiqc` is an invaluable tools for quickly examining the
overall sequencing quality

## Aligning with Salmon

Assuming you have already built or downloaded a Salmon index then performing 
quantification with Salmon is run with a simple shell script:

```
#!/usr/bin/env bash

SAMPLE_IDS=sample-ids.txt
FQ_DIR=path/to/fastq/files
OUT_DIR=quants
SALMON_IDX=path/to/salmon_idx
THREADS=48

mkdir -p $OUT_DIR

for SAMPLE_ID in $(cat $SAMPLE_IDS); do
  salmon quant \
     -i $SALMON_IDX \
     -l A \
     -1 $FQ_DIR/${SAMPLE_ID}_R1.fq.gz \
     -2 $FQ_DIR/${SAMPLE_ID}_R2.fq.gz \
     --validateMappings \
     --gcBias \
     --seqBias \
     --threads $THREADS \
     -o $OUT_DIR/${SAMPLE_ID}_quants;
done
```

Where sample-ids.txt contains the basenames of the fastq files like:

```
control1
control2
control3
treatment1
treatment2
treatment3
```

## Load libraries

```{r}
suppressPackageStartupMessages(library(coriell))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tximportData))
suppressPackageStartupMessages(library(tximport))
suppressPackageStartupMessages(library(edgeR))
suppressPackageStartupMessages(library(PCAtools))
suppressPackageStartupMessages(library(clusterProfiler))
suppressPackageStartupMessages(library(org.Hs.eg.db))
suppressPackageStartupMessages(library(fgsea))
suppressPackageStartupMessages(library(msigdb))
suppressPackageStartupMessages(library(ExperimentHub))
```

## Differential Gene Expression Analysis

For this sample analysis we will use the included data in the `tximportData` 
package.

```{r}
# Select the directory where the quants files are stored
dir <- system.file("extdata", package = "tximportData")

# Read in the sample metadata
samples <- read.table(file.path(dir, "samples.txt"), header = TRUE)
rownames(samples) <- samples$run

# List all quant files in dir
files <- file.path(dir, "salmon", samples$run, "quant.sf.gz")

# Name the files by their run ID
names(files) <- regmatches(files, regexpr("ERR[0-9]+", files))

# Read in the tx2gene file that maps transcripts to genes
tx2gene <- read.csv(file.path(dir, "tx2gene.gencode.v27.csv"))
```

In your code, quant files will be saved in separate folders per sample if you
followed the example script from above. The command to find these files might
look more like:

```{r echo=TRUE, eval=FALSE}
files <- list.files(
  path = "/path/to/OUT_DIR",
  pattern = "quant.sf",
  recursive = TRUE,
  full.names = TRUE
)
```

### Import counts with `tximport`

We often want to perform differential expression not on the transcript level but 
the gene-level. This requires summarizing the counts and applying an offset to 
adjust for length biases. The easiest way to import counts with an offset is to
use the `tximport` function with the "scaledTPM" option.

```{r}
# Import the counts using tximport
txi <- tximport(
  files, 
  type = "salmon", 
  tx2gene = tx2gene, 
  countsFromAbundance = "scaledTPM"
  )

# Extract the counts matrix from the txi object
counts <- txi$counts
```

### Filter the count matrix

It is often only of interest to study the protein coding genes. To get the protein 
coding genes and the gene symbols all in one go it is usually easiest to work with
GTF files directly. 

The example data was generated using GENCODE v27 annotations on hg19. We can download 
this annotation file and use it to select the protein coding genes as well as extract
other useful information about the genes.

```{r}
# Download and import the annotations
url <- "https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.basic.annotation.gtf.gz"
gtf_file <- "~/Downloads/gencode.v27lift37.basic.annotation.gtf.gz"

if (!file.exists(gtf_file)) {
  download.file(url, gtf_file)
}
gtf <- data.frame(rtracklayer::import(gtf_file))

# Extract all of the protein coding genes from the GTF
protein_coding <- gtf[gtf$type == "gene" & gtf$gene_type == "protein_coding", "gene_id"]

# Removing trailing ids if present
protein_coding <- unique(gsub("_[0-9]+$", "", protein_coding))

# Filter the count matrix for protein coding genes
counts <- counts[rownames(counts) %in% protein_coding, ]
```

### Checking the library distributions

It is always good to check to see if the sequenced libraries are behaving as
expected. The `coriell` package has a few diagnostic plots to help with this.

The first diagnostic plot is the `plot_boxplot()` function which will plot 
boxplots for each sample in a matrix. Importantly, the `plot_boxplot()` function
also allows the user to examine the relative log expression values for each 
sample in order to assess technical factors that may be influencing each 
library. RLE plots should show sample distributions centered on zero with 
similar distributions of outlier values.

```{r}
# Calculate the log2 counts per million for each sample
logcounts <- edgeR::cpm(counts, log = TRUE, prior.count = 1)

# Show the distribution of the logcounts for each sample
plot_boxplot(logcounts, metadata = samples, fillBy = "pop", rle = TRUE, 
             outlier.shape = NA) +
  labs(title = "Relative Log Expression",
       x = "Sample",
       y = "RLE") +
  scale_y_continuous(limits = c(-1.5, 1.5)) +
  theme_coriell()
```

Another diagnostic plot is the `plot_distribution()` function. This function
creates a density plot for each sample allowing the user to view the density 
of the counts for all samples.

```{r}
plot_density(logcounts, metadata = samples, colBy = "pop") +
  labs(title = "Density plot",
       x = "log2CPM") +
  theme_coriell()
```

Another useful diagnostic plot is to view the euclidean distances for the 
unscaled counts between samples. This plot gives you an idea of how similar 
samples are to each other on an absolute level. This can be accomplished with 
the `plot_dist()` function.

```{r}
plot_dist(counts, metadata = samples[, "pop", drop = FALSE])
```

### Analysis with `edgeR`

Downstream analysis of count data can be performed in `edgeR`. Since this 
example data does not contain any actual groups i will create artificial groups
only for the purpose of demonstrating the steps involved in a simple 
differential expression analysis.

```{r message=FALSE}
# Add an arbitrary group factor to the samples
samples$group <- gl(2, 3, labels = c("Control", "Treatment"))

# Specify group based design
design <- model.matrix(~ 0 + group, data = samples)
colnames(design) <- gsub("group", "", colnames(design))

# Import counts into edger
y <- DGEList(counts, samples = samples, group = samples$group)

# Filter for expression
keep <- filterByExpr(y, design)
y <- y[keep, ]

# Calculate normalization factors
y <- calcNormFactors(y, method = "TMM")

# Estimate genewise dispersion
y <- estimateDisp(y, design = design, robust = TRUE)

# Fit the model
fit <- glmQLFit(y, design, robust = TRUE)

# Specify contrasts to test
con <- makeContrasts(TvC = Treatment - Control, levels = design)

# Test for differential expression
qlf <- glmQLFTest(fit, contrast = con[, "TvC"])

# Extract the test results as a data.frame
qlf_df <- edger_to_df(qlf)
```

## PCA

We can perform Principal Components Analysis on the normalized logcounts using 
functions from `edgeR` and `PCAtools`. See the [PCAtools vignette](https://bioconductor.org/packages/devel/bioc/vignettes/PCAtools/inst/doc/PCAtools.html) 
for more useful functions.

```{r message=FALSE}
# Calculate the normalized log counts per million
logcounts <- cpm(y, log = TRUE)

# Perform PCA on the 20% most variable logcounts
pca.res <- pca(logcounts, metadata = samples, removeVar = 0.8, scale = TRUE)
```

Plot the pca biplot and color by the arbitrary group variable.

```{r}
biplot(
  pca.res,
  colby = "group",
  hline = 0,
  vline = 0,
  hlineType = 2,
  vlineType = 2,
  legendPosition = "bottom",
  title = "PCA on logcounts",
  caption = "20% Most Variable Features"
)
```

## Heatmap

The `coriell` package has a wrapper around `pheatmap()` that sets sensible 
defaults for sequencing data. Any argument that can be passed to `pheatmap()` 
can be passed to the `quickmap()` function to override the defaults. The 
`quickmap()` function also allows the user to remove low variance features and
fix the scales of the the color so that extreme values do not wash out the 
heatmap.

```{r}
# Create a dataframe of annotations to use
col_df <- samples[, "group", drop = FALSE]

# Create color scheme for treatment conditions
ann_colors <- list(group = c("Control" = "steelblue", "Treatment" = "firebrick"))

# Plot the heatmap, passing additional args to pheatmap
quickmap(
  logcounts,
  removeVar = 0.8,
  fix_extreme = TRUE,
  annotation_col = col_df,
  annotation_colors = ann_colors,
  main = "20% Most Variable Genes"
)
```

## Volcano Plots

The `coriell` contains functions for plotting volcano plots and displaying
the counts of up and down regulated genes on the plots. The aesthetics of the
plots produced by `plot_volcano()` and `plot_md()` below can be modified. Please 
check the function documentation for details.

Of course, for this analysis there are no differentially expressed genes because 
the groups are arbitrary. However, we can still demonstrate the functions from 
the `coriell` package.

```{r}
# Create a volcano plot with the default settings
plot_volcano(qlf_df) + 
  ggtitle("Volcano Plot of Differential Expression Results")
```

For a real dataset with differences the plot looks more like:

```{r}
# GSE161650_de is a dataset built into the coriell package for demonstrations
plot_volcano(GSE161650_de, fdr = 0.05, lfc = log2(1.5))
```

## MA Plots

Likewise, MA plots can be drawn with `plot_md()`

```{r}
plot_md(qlf_df) + 
  ggtitle("MA Plot of Differential Expression Results")
```

and again for real data:

```{r}
plot_md(GSE161650_de, fdr = 0.05, lfc = log2(1.5))
```

## Gene ontology analysis

Once you have a vector of genes that is interesting you can see if those genes 
are over-represented in a particular pathway. The easiest way to do this is
with the `clusterProfiler` package.

```{r, message=FALSE}
# Extract a vector of the up-regulated genes
up_genes <- subset(
  GSE161650_de, 
  FDR < 0.05 & logFC > 0, 
  select = feature_id, 
  drop = TRUE
  )

# Extract a vector of the down-regulated genes
down_genes <- subset(
  GSE161650_de, 
  FDR < 0.05 & logFC < 0, 
  select = feature_id, 
  drop = TRUE
  )

# Test each set for over-representation of all ontologies
ego_up <- enrichGO(
  up_genes,
  OrgDb = org.Hs.eg.db,
  keyType = "SYMBOL",
  ont = "ALL",
  pool = TRUE,
  readable = TRUE
)

ego_down <- enrichGO(
  down_genes,
  OrgDb = org.Hs.eg.db,
  keyType = "SYMBOL",
  ont = "ALL",
  pool = TRUE,
  readable = TRUE
)
```

We can visualize the over-representation results with dotplots

```{r}
dotplot(ego_up) + labs(title = "Up-regulated genes")
dotplot(ego_down) + labs(title = "Down-regulated genes")
```

To view the results of the over-representation test as a data.frame simply 
coerce:

```{r}
# Convert the ego results to a data.frame
ego_df <- data.frame(ego_up)
head(ego_df)
```

## Gene set enrichment analysis

We can perform gene set enrichment on a list of genes and their ranks from a 
differential expression analysis using the `fgsea` package and gene sets from 
the Molecular Signatures Database.

```{r}
# Get the msigDB data
msigdb.hs <- getMsigdb(org = "hs", id = "SYM", version = "7.4")

# Subset for the hallmark gene set
hallmark <- subsetCollection(msigdb.hs, "h")

# Convert to a simple list for fgsea
hallmark <- geneIds(hallmark)

# Create a ranking stat vector -- use coriell example data
stats <- with(GSE161650_de, logFC * -log10(PValue))
names(stats) <- GSE161650_de$feature_id

# Perform GSEA on all of the hallmark sets with fgsea
fgsea.results <- fgsea(
  hallmark,
  stats,
  nPermSimple = 1e4,
  eps = 0.0
)
```

The results of the GSEA test can be viewed as a table:

```{r}
head(fgsea.results)
```

Or selected pathways can be plotted with:

```{r}
plotEnrichment(hallmark[["HALLMARK_APOPTOSIS"]], stats) +
  labs(title = "HALLMARK APOPTOSIS") +
  theme_coriell()
```
