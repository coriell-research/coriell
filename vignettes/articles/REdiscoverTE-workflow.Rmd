---
title: "REdiscoverTE Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{REdiscoverTE Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This document outlines my general steps for extracting reads in fastq format 
from BAM files, aligning them to the REdiscoverTE transcriptome, and quantifying
their counts with `tximport`

## 1. Get data from TCGA

Typically I have to do this workflow for TCGA samples so include a step here to
document downloading data from TCGA.

```{bash eval=FALSE, include=TRUE}
MANIFEST=/path/to/gdc_manifest.txt
TOKEN=/path/to/tcga-token-file.txt
BAM_DIR=/path/to/save/bamfiles
PROC=12

# Download all files from the manifest into BAM_DIR using 12 processes
gdc-client download \
  --manifest $MANIFEST \
  --token-file $TOKEN \
  --dir $BAM_DIR \
  --n-processes $PROC
```

## 2. Extract fastq files from BAMs

Use `parallel` to extract fastq reads from all bamfiles found by `find` in the 
`$BAM_DIR` defined above. `samtools collate`  groups the two reads in a read 
pair and outputs an uncompressed BAM stream. `samtools fastq` consumes this 
stream and outputs the reads pairs to separate files. Unpaired reads are 
written to /dev/null.

```{bash eval=FALSE, include=TRUE}
FQ_DIR=/path/to/save/fastq_files

# Extract Reads
parallel --jobs $PROC "samtools collate -u -O {} /tmp/{/.}_tmp | samtools fastq - -1 $FQ_DIR/{/.}.1.fq.gz -2 $FQ_DIR/{/.}.2.fq.gz -0 /dev/null -n" ::: $(find $BAM_DIR -iname "*.bam")
```

## 3. Align to REdiscoverTE transcriptome

This assumes you have a text file with basenames for the sample fastq files like:

**sample-names.txt**

```{bash eval=FALSE, include=TRUE}
sample1
sample2
sample3
sample4
```

```{bash eval=FALSE, include=TRUE}
IDX=/mnt/data/gdata/human/REdiscoverTE_hg38/REdiscoverTE_hg38_GFP/REdiscoverTE_GFP_salmon_idx/
OUT_DIR=/path/to/qaunts
FQ_DIR=/path/to/fastq_files
SAMPLES=/path/to/sample-names.txt
THREADS=12

for SAMPLE in $(cat $SAMPLES); do
  salmon quant \
    -i $IDX \
    -l 'A' \
    -p $THREADS \
    --gcBias \
    --seqBias \
    ---validateMappings \
    -1 $FQ_DIR/${SAMPLE}.1.fq.gz \
    -2 $FQ_DIR/${SAMPLE}.fq.gz \
    -o $OUT_DIR/${SAMPLE}_quants;
done
```

## 4. Import counts into `R`

The next step imports the quant files from `salmon` into R for all mapped samples 
and creates a matrix of gene-level counts that can be used in downstream analyses. 

It is necessary to use `tximport` for this step instead of raw counts from the 
quant.sf files to account for differences in aggregation due to transcript 
differences between samples. 

```{r eval=FALSE, include=TRUE}
library(tximport)


quant_files <- list.files(
  path = "/path/to/quants",
  pattern = "quant.sf",
  recursive = TRUE,
  full.names = TRUE
)

# Name each file with the basename of the sample -- this should be changed
# names() will be used as the column names in the final count matrix
names(quant_files) <- desired_vector_of_sample_names

# tximport maps gene ids (md5sums) to genes and RE sub-families
tx2gene <- readRDS("/mnt/data/gdata/human/REdiscoverTE_hg38/tx2gene_REdiscoverTE.rds")

# Import counts for all files with tximport -- set scaledTPM to account for tx usage
txi <- tximport(
  quant_files,
  type = "salmon",
  countsFromAbundance = "scaledTPM",
  tx2gene = tx2gene,
  importer = data.table::fread
)

# Extract counts from the txi object
counts <- txi$counts

# Remove any all 0 rows to save some space
counts <- counts[rowSums(counts) > 0, ]
```

We download and import the GENCODE v26 gtf file used in the creation of the 
REdiscoverTE index in order to define protein coding genes. Then we split the 
`counts` matrix into genes, exonic, intronic, and intergenic repeat element 
sub-families from the five 'main' TE classes (LINE, SINE, LTR, SVA, DNA).

The final `counts` matrix used in downstream analysis contains the gene expression
and the expression of REs from intergenic and intronic regions. 

```{r eval=FALSE, include=TRUE}
# Get the reference GTF file and extract a vector of protein coding genes
url <- "https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_26/gencode.v26.annotation.gtf.gz"
gtf <- data.frame(rtracklayer::import(url))
coding <- unique(gtf[gtf$type == "gene" & gtf$gene_type == "protein_coding", "gene_name"])

# Filter matrix for protein coding genes
genes <- counts[rownames(counts) %chin% coding, ]

# Filter matrix for repeats from five 'main' classes/families
repeats <- counts[grepl("^LINE\\.|^SINE\\.|^LTR\\.|.*\\.SVA\\..*|^DNA\\.", rownames(counts)), ]

# Split into repeat types by location
intergenic <- repeats[grepl("__intergenic", rownames(repeats)), ]
exonic <- repeats[grepl("__exon", rownames(repeats)), ]
intronic <- repeats[grepl("__intron", rownames(repeats)), ]

# Only use repeats that are not located in exons
repeats <- rbind(intronic, intergenic)

# Strip the __intron __intergenic labels and sum counts for each element
elem <- gsub("__intergenic|__intron", "", rownames(repeats))
repeats <- rowsum(repeats, group = elem, reorder = FALSE)

# Bind all back into a single matrix, ready for downstream analysis
counts <- rbind(genes, repeats)
```
